\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\citation{energy_cost_ml1,energy_cost_ml2}
\citation{trainingphysicalneuralnetworks}
\citation{}
\citation{}
\citation{}
\HyPL@Entry{0<</P(\376\377\0001)>>}
\newlabel{FirstPage}{{}{1}{}{section*.1}{}}
\newlabel{FirstPage@cref}{{}{[1][1][]1}}
\@writefile{toc}{\contentsline {title}{Efficient Machine Learning in a Memristor Network}{1}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {abstract}{Abstract}{1}{section*.1}\protected@file@percent }
\newlabel{sec:Intro}{{I}{1}{}{section*.3}{}}
\newlabel{sec:Intro@cref}{{[section][1][]I}{[1][1][]1}}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section*.3}\protected@file@percent }
\citation{Rene_IonicNeuromorphic}
\citation{Rene_PressureSensitive}
\citation{Rene_IonicNeuromorphic}
\citation{Rene_IonicNeuromorphic}
\HyPL@Entry{1<</P(\376\377\0002)>>}
\newlabel{sec:memristor_network}{{II}{2}{}{section*.4}{}}
\newlabel{sec:memristor_network@cref}{{[section][2][]II}{[1][2][]2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Memristor Network}{2}{section*.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A schematic representation of the conical fluidic memristor. A cone of lenght $L$, base radius $R_b$ and tip radius $R_t$ with charged surface connnects two bulk reservoirs of a 1:1 electrolyte in an acqueous solution. The bulk density in the base $\rho _b$ differs from the bulk density in the tip $\rho _t$. At the far side of the memristor, an electrical potential and pressure drop are applied. Overall, this results in a chemical, electrical and mechanical sensistive system.}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:memristor_scheme}{{1}{2}{A schematic representation of the conical fluidic memristor. A cone of lenght $L$, base radius $R_b$ and tip radius $R_t$ with charged surface connnects two bulk reservoirs of a 1:1 electrolyte in an acqueous solution. The bulk density in the base $\rho _b$ differs from the bulk density in the tip $\rho _t$. At the far side of the memristor, an electrical potential and pressure drop are applied. Overall, this results in a chemical, electrical and mechanical sensistive system}{figure.1}{}}
\newlabel{fig:memristor_scheme@cref}{{[figure][1][]1}{[1][2][]2}}
\newlabel{eq:rho_average}{{1}{2}{}{equation.2.1}{}}
\newlabel{eq:rho_average@cref}{{[equation][1][]1}{[1][2][]2}}
\newlabel{eq:eqofmotconductance}{{2}{2}{}{equation.2.2}{}}
\newlabel{eq:eqofmotconductance@cref}{{[equation][2][]2}{[1][2][]2}}
\citation{}
\HyPL@Entry{2<</P(\376\377\0003)>>}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An example of a network of five nodes connected by six memristors. The nodes are divided in input nodes (green circles), hidden nodes (gray nodes) and output nodes (purple circles) each of them is characterized by a triplet of physical quantities, representing the potential, pressure, and density. Th resulting stimuli on the memristor is given by the difference between base and tip signal, it thus depends on the oreintation of the memristor. In the case of the memristor that connects the first and the second node, for example, the exteranl stimuli are $\Delta V = V_2 - V_1$, $\Delta P = P_2 - P_1$ and $\Delta \rho = \rho _2 - \rho _1$. The zig-zag lines directed towards the input nodes indicate where the electrical signal is applied, while the zig-zag lines pointing outwards from the nodes indicate where the electrical signal is measured.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:memristor_network}{{2}{3}{An example of a network of five nodes connected by six memristors. The nodes are divided in input nodes (green circles), hidden nodes (gray nodes) and output nodes (purple circles) each of them is characterized by a triplet of physical quantities, representing the potential, pressure, and density. Th resulting stimuli on the memristor is given by the difference between base and tip signal, it thus depends on the oreintation of the memristor. In the case of the memristor that connects the first and the second node, for example, the exteranl stimuli are $\Delta V = V_2 - V_1$, $\Delta P = P_2 - P_1$ and $\Delta \rho = \rho _2 - \rho _1$. The zig-zag lines directed towards the input nodes indicate where the electrical signal is applied, while the zig-zag lines pointing outwards from the nodes indicate where the electrical signal is measured}{figure.2}{}}
\newlabel{fig:memristor_network@cref}{{[figure][2][]2}{[1][3][]3}}
\newlabel{sec:training}{{III}{3}{}{section*.5}{}}
\newlabel{sec:training@cref}{{[section][3][]III}{[1][3][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Training Algorithm for a Memristor Network}{3}{section*.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (a) Memristor network with weights defined in the nodes. (b) Memristor network where wegiths characterize each edge.}}{3}{figure.3}\protected@file@percent }
\newlabel{fig:two_types_weights}{{3}{3}{(a) Memristor network with weights defined in the nodes. (b) Memristor network where wegiths characterize each edge}{figure.3}{}}
\newlabel{fig:two_types_weights@cref}{{[figure][3][]3}{[1][3][]3}}
\citation{steepest_descent_book}
\HyPL@Entry{3<</P(\376\377\0004)>>}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces }}{4}{figure.4}\protected@file@percent }
\newlabel{fig:training_scheme}{{4}{4}{}{figure.4}{}}
\newlabel{fig:training_scheme@cref}{{[figure][4][]4}{[1][3][]4}}
\newlabel{eq:weight_update}{{4}{4}{}{equation.3.4}{}}
\newlabel{eq:weight_update@cref}{{[equation][4][]4}{[1][4][]4}}
\newlabel{eq:gradient_cost_func}{{5}{4}{}{equation.3.5}{}}
\newlabel{eq:gradient_cost_func@cref}{{[equation][5][]5}{[1][4][]4}}
\HyPL@Entry{4<</P(\376\377\0005)>>}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Training a Memristor Voltage Divider}{5}{section*.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces }}{5}{figure.5}\protected@file@percent }
\newlabel{fig:vd_scheme}{{5}{5}{}{figure.5}{}}
\newlabel{fig:vd_scheme@cref}{{[figure][5][]5}{[1][5][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces (a) Behaviour of the cost function during the training of the voltage divider. Different colors indicate that the training is done with a specific choise of training weights, as indiacted in the legend. (b) Pressures imposed on the three nodes of the voltage divider during training. The inset shows the relaxation to the steady state of the output voltage $V_2$ to the desired value $V_D$ when the pressures imposed are the values obtained in the last training step, and the input nodes are stimulated with fixed voltage. (c) Ion concentration desnities imposed on the three nodes of the voltage divider during training. (d) Length of the memristors during training. (e) Base radius of the memristors during training.}}{5}{figure.6}\protected@file@percent }
\newlabel{fig:mse_weights_vd}{{6}{5}{(a) Behaviour of the cost function during the training of the voltage divider. Different colors indicate that the training is done with a specific choise of training weights, as indiacted in the legend. (b) Pressures imposed on the three nodes of the voltage divider during training. The inset shows the relaxation to the steady state of the output voltage $V_2$ to the desired value $V_D$ when the pressures imposed are the values obtained in the last training step, and the input nodes are stimulated with fixed voltage. (c) Ion concentration desnities imposed on the three nodes of the voltage divider during training. (d) Length of the memristors during training. (e) Base radius of the memristors during training}{figure.6}{}}
\newlabel{fig:mse_weights_vd@cref}{{[figure][6][]6}{[1][5][]5}}
\HyPL@Entry{5<</P(\376\377\0006)>>}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces (a) The trainiang of a memristor voltage divider to a set of desired voltage outputs $V_D = {1V, 3V, 4V}$, indicated by dashed light purple lines. The output voltage $V_2$, indicated by dark purple dots, adapts to the desired output during the training. The input voltages $V_1$ and $V_3$ are constant at $5V$ and $0V$ respectively. (b) The dots with different shades of gray show the values of pressures, chosen as weights, imposed on the three nodes during training.}}{6}{figure.7}\protected@file@percent }
\newlabel{fig:evolution_targets}{{7}{6}{(a) The trainiang of a memristor voltage divider to a set of desired voltage outputs $V_D = {1V, 3V, 4V}$, indicated by dashed light purple lines. The output voltage $V_2$, indicated by dark purple dots, adapts to the desired output during the training. The input voltages $V_1$ and $V_3$ are constant at $5V$ and $0V$ respectively. (b) The dots with different shades of gray show the values of pressures, chosen as weights, imposed on the three nodes during training}{figure.7}{}}
\newlabel{fig:evolution_targets@cref}{{[figure][7][]7}{[1][5][]6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Training a memristor network}{6}{section*.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Network to the right has inputs $[5,0]$ and desired outputs $[3, 4]$, delta weights a third of their intial value and learning rates $1e^{-5}, 1e^{-4}, 1e^{2}$. The network to the right has $[5,1,0]$ and output $[3,4,2]$}}{6}{figure.8}\protected@file@percent }
\newlabel{fig:mse_general}{{8}{6}{Network to the right has inputs $[5,0]$ and desired outputs $[3, 4]$, delta weights a third of their intial value and learning rates $1e^{-5}, 1e^{-4}, 1e^{2}$. The network to the right has $[5,1,0]$ and output $[3,4,2]$}{figure.8}{}}
\newlabel{fig:mse_general@cref}{{[figure][8][]8}{[1][6][]6}}
\HyPL@Entry{6<</P(\376\377\0007)>>}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Linear Regression}{7}{section*.8}\protected@file@percent }
\newlabel{eq:linear_relationship}{{6}{7}{}{equation.3.6}{}}
\newlabel{eq:linear_relationship@cref}{{[equation][6][]6}{[1][7][]7}}
\bibdata{paperNotes,biblio}
\HyPL@Entry{7<</P(\376\377\0008)>>}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusion}{8}{section*.9}\protected@file@percent }
\@writefile{toc}{\appendix }
\bibcite{energy_cost_ml1}{{1}{}{{}}{{}}}
\bibcite{energy_cost_ml2}{{2}{}{{}}{{}}}
\bibcite{trainingphysicalneuralnetworks}{{3}{}{{}}{{}}}
\bibcite{Rene_IonicNeuromorphic}{{4}{}{{}}{{}}}
\bibcite{Rene_PressureSensitive}{{5}{}{{}}{{}}}
\bibcite{steepest_descent_book}{{6}{}{{}}{{}}}
\bibstyle{unsrt}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\HyPL@Entry{8<</P(\376\377\0009)>>}
\@writefile{toc}{\contentsline {section}{\numberline {}References}{9}{section*.10}\protected@file@percent }
\newlabel{LastBibItem}{{6}{9}{}{section*.10}{}}
\newlabel{LastBibItem@cref}{{[section][4][]IV}{[1][9][]9}}
\newlabel{LastPage}{{}{9}{}{}{}}
\gdef \@abspage@last{9}
